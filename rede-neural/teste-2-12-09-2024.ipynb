{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fernando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0809 - val_loss: 0.0061\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0728 - val_loss: 0.0152\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0437 - val_loss: 0.0273\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0265 - val_loss: 0.0385\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0213 - val_loss: 0.0430\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0126 - val_loss: 0.0406\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0164 - val_loss: 0.0321\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0148 - val_loss: 0.0213\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0087 - val_loss: 0.0035\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0055 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0064 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0060 - val_loss: 0.0144\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0110 - val_loss: 0.0140\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0082 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 5.6401e-04 - val_loss: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 7.5622e-04 - val_loss: 0.0068\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0019 - val_loss: 0.0084\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0024 - val_loss: 0.0099\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0044 - val_loss: 0.0107\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0025 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0035 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0027 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0022 - val_loss: 0.0101\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0013 - val_loss: 0.0092\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0017 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0076\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0023 - val_loss: 0.0069\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 6.9527e-04 - val_loss: 0.0050\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0038\n",
      "Loss: 0.0037686717696487904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Passo 1: Carregar os dados\n",
    "df = pd.read_csv('base_unificada_com_casos.csv')\n",
    "\n",
    "# Passo 2: Agrupar por país\n",
    "paises = df['Local'].unique()\n",
    "\n",
    "# Vamos escolher um país específico para o exemplo\n",
    "pais = 'Albania'\n",
    "df_pais = df[df['Local'] == pais]\n",
    "\n",
    "# Passo 3: Selecionar as colunas relevantes para o modelo\n",
    "features = ['BCG', 'Hib3', 'DTP3', 'Saneamento Seguro (%)', 'Numero Total de Imigrantes',\n",
    "            'Gini (Indice de Desigualdade no Pais)', 'Populacao', 'Taxa de Extrema Pobreza (%)', \n",
    "            'Numero de Usuario de Internet']\n",
    "target = 'Numero de Casos de Infeccoes Respiratorios e Tuberculose'\n",
    "\n",
    "# Normalizar os dados para a rede neural (MinMaxScaler)\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_pais[features + [target]])\n",
    "\n",
    "# Passo 4: Criar as sequências temporais (janelas de tempo)\n",
    "def create_sequences(data, sequence_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length, :-1])\n",
    "        y.append(data[i+sequence_length, -1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Definir o tamanho da sequência\n",
    "sequence_length = 5  # Pode ajustar conforme o desempenho\n",
    "X, y = create_sequences(df_scaled, sequence_length)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Passo 5: Construir a rede LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Passo 6: Treinar o modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Passo 7: Avaliação do modelo\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}')\n",
    "\n",
    "# Previsões\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Como o scaler foi ajustado em todas as colunas (features + target), precisamos escalonar apenas o target de volta\n",
    "# Pegamos os dados escalonados do target, e não tentamos concatenar as previsões com as features\n",
    "predictions_rescaled = scaler.inverse_transform(\n",
    "    np.concatenate([np.zeros((predictions.shape[0], X_test.shape[2])), predictions], axis=1))[:, -1]\n",
    "\n",
    "# Visualizar previsões e valores reais\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_pais['Ano'][train_size+sequence_length:], y_test, label='Real')\n",
    "plt.plot(df_pais['Ano'][train_size+sequence_length:], predictions_rescaled, label='Previsto')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando com seq_len=3, units=32, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1799 - val_loss: 0.0032\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1546 - val_loss: 0.0027\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1384 - val_loss: 0.0025\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1269 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1236 - val_loss: 0.0034\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1090 - val_loss: 0.0046\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1014 - val_loss: 0.0061\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0749 - val_loss: 0.0081\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0628 - val_loss: 0.0104\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0592 - val_loss: 0.0132\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0633 - val_loss: 0.0164\n",
      "Epoch 12/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0520 - val_loss: 0.0198\n",
      "Epoch 13/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0337 - val_loss: 0.0233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0025\n",
      "Loss: 0.002506497548893094\n",
      "Treinando com seq_len=3, units=32, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1764 - val_loss: 0.0092\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1596 - val_loss: 0.0127\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1529 - val_loss: 0.0170\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1277 - val_loss: 0.0220\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1255 - val_loss: 0.0277\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1086 - val_loss: 0.0339\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1186 - val_loss: 0.0408\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0990 - val_loss: 0.0477\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0896 - val_loss: 0.0547\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0780 - val_loss: 0.0614\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0639 - val_loss: 0.0682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0092\n",
      "Loss: 0.009179661981761456\n",
      "Treinando com seq_len=3, units=32, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.2043 - val_loss: 0.0025\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1863 - val_loss: 0.0026\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1771 - val_loss: 0.0030\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1589 - val_loss: 0.0037\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1494 - val_loss: 0.0048\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1343 - val_loss: 0.0062\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1308 - val_loss: 0.0081\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1313 - val_loss: 0.0104\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0998 - val_loss: 0.0131\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0882 - val_loss: 0.0162\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0784 - val_loss: 0.0197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0025\n",
      "Loss: 0.002534860745072365\n",
      "Treinando com seq_len=3, units=64, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.2122 - val_loss: 0.0047\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1836 - val_loss: 0.0030\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1701 - val_loss: 0.0025\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1361 - val_loss: 0.0029\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1228 - val_loss: 0.0044\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1043 - val_loss: 0.0066\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0955 - val_loss: 0.0097\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0752 - val_loss: 0.0136\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0651 - val_loss: 0.0181\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0560 - val_loss: 0.0232\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0381 - val_loss: 0.0286\n",
      "Epoch 12/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0301 - val_loss: 0.0339\n",
      "Epoch 13/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0337 - val_loss: 0.0389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0025\n",
      "Loss: 0.0024568606168031693\n",
      "Treinando com seq_len=3, units=64, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1691 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1464 - val_loss: 0.0025\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1199 - val_loss: 0.0049\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0928 - val_loss: 0.0099\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0729 - val_loss: 0.0175\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0623 - val_loss: 0.0268\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0518 - val_loss: 0.0376\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0408 - val_loss: 0.0485\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0397 - val_loss: 0.0574\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0290 - val_loss: 0.0631\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0289 - val_loss: 0.0636\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0194 - val_loss: 0.0603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0025\n",
      "Loss: 0.002527396660298109\n",
      "Treinando com seq_len=3, units=64, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.2041 - val_loss: 0.0028\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1717 - val_loss: 0.0024\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1571 - val_loss: 0.0036\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1190 - val_loss: 0.0064\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1029 - val_loss: 0.0108\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0809 - val_loss: 0.0169\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0586 - val_loss: 0.0244\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0546 - val_loss: 0.0327\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0375 - val_loss: 0.0414\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0351 - val_loss: 0.0494\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0288 - val_loss: 0.0556\n",
      "Epoch 12/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0234 - val_loss: 0.0595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0024\n",
      "Loss: 0.002376857679337263\n",
      "Treinando com seq_len=3, units=128, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1843 - val_loss: 0.0029\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1469 - val_loss: 0.0030\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1042 - val_loss: 0.0070\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0735 - val_loss: 0.0153\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0472 - val_loss: 0.0277\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0314 - val_loss: 0.0424\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0206 - val_loss: 0.0553\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0121 - val_loss: 0.0605\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0193 - val_loss: 0.0544\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0159 - val_loss: 0.0422\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0265 - val_loss: 0.0269\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0029\n",
      "Loss: 0.0029305038042366505\n",
      "Treinando com seq_len=3, units=128, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.2106 - val_loss: 0.0033\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1602 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1143 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0917 - val_loss: 0.0142\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0665 - val_loss: 0.0257\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0457 - val_loss: 0.0389\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0277 - val_loss: 0.0516\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0229 - val_loss: 0.0592\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0206 - val_loss: 0.0580\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0204 - val_loss: 0.0495\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0238 - val_loss: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0198 - val_loss: 0.0220\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0028\n",
      "Loss: 0.0027536822017282248\n",
      "Treinando com seq_len=3, units=128, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1684 - val_loss: 0.0028\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1207 - val_loss: 0.0032\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0914 - val_loss: 0.0081\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0593 - val_loss: 0.0175\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0366 - val_loss: 0.0311\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0233 - val_loss: 0.0449\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0147 - val_loss: 0.0546\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0141 - val_loss: 0.0562\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0181 - val_loss: 0.0485\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0222 - val_loss: 0.0357\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0208 - val_loss: 0.0222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0028\n",
      "Loss: 0.0028008201625198126\n",
      "Treinando com seq_len=5, units=32, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1098 - val_loss: 0.0042\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0903 - val_loss: 0.0029\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0785 - val_loss: 0.0023\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0619 - val_loss: 0.0023\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0514 - val_loss: 0.0030\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0322 - val_loss: 0.0044\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0184 - val_loss: 0.0065\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0176 - val_loss: 0.0089\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0076 - val_loss: 0.0142\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0120 - val_loss: 0.0166\n",
      "Epoch 12/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0082 - val_loss: 0.0186\n",
      "Epoch 13/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0083 - val_loss: 0.0195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0023\n",
      "Loss: 0.0023137242533266544\n",
      "Treinando com seq_len=5, units=32, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1207 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1028 - val_loss: 0.0043\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1022 - val_loss: 0.0068\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0698 - val_loss: 0.0099\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0673 - val_loss: 0.0136\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0571 - val_loss: 0.0178\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0471 - val_loss: 0.0221\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0333 - val_loss: 0.0263\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0264 - val_loss: 0.0304\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0213 - val_loss: 0.0346\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0170 - val_loss: 0.0374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0027\n",
      "Loss: 0.0027372646145522594\n",
      "Treinando com seq_len=5, units=32, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0636 - val_loss: 0.0161\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0593 - val_loss: 0.0206\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0519 - val_loss: 0.0229\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0377 - val_loss: 0.0243\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0230 - val_loss: 0.0249\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0232 - val_loss: 0.0237\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0162 - val_loss: 0.0217\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0140 - val_loss: 0.0186\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0172 - val_loss: 0.0112\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0140 - val_loss: 0.0078\n",
      "Epoch 12/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0111 - val_loss: 0.0054\n",
      "Epoch 13/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0104 - val_loss: 0.0038\n",
      "Epoch 14/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 15/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0090 - val_loss: 0.0040\n",
      "Epoch 16/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 17/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0100 - val_loss: 0.0074\n",
      "Epoch 18/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 19/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0050 - val_loss: 0.0110\n",
      "Epoch 20/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 21/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 22/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0073 - val_loss: 0.0121\n",
      "Epoch 23/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 24/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0062 - val_loss: 0.0105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0034\n",
      "Loss: 0.0034499410539865494\n",
      "Treinando com seq_len=5, units=64, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1167 - val_loss: 0.0108\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0922 - val_loss: 0.0048\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0645 - val_loss: 0.0028\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0461 - val_loss: 0.0042\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0241 - val_loss: 0.0084\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0188 - val_loss: 0.0131\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0134 - val_loss: 0.0162\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0116 - val_loss: 0.0171\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0178 - val_loss: 0.0106\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0127 - val_loss: 0.0065\n",
      "Epoch 12/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 13/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0028\n",
      "Loss: 0.0027766735292971134\n",
      "Treinando com seq_len=5, units=64, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1409 - val_loss: 0.0024\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1165 - val_loss: 0.0035\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0913 - val_loss: 0.0061\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0546 - val_loss: 0.0099\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0369 - val_loss: 0.0150\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0219 - val_loss: 0.0199\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0128 - val_loss: 0.0234\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0084 - val_loss: 0.0242\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0130 - val_loss: 0.0218\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0087 - val_loss: 0.0176\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0131 - val_loss: 0.0126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0024\n",
      "Loss: 0.002448127605021\n",
      "Treinando com seq_len=5, units=64, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1425 - val_loss: 0.0040\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0990 - val_loss: 0.0107\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0768 - val_loss: 0.0212\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0513 - val_loss: 0.0349\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0398 - val_loss: 0.0483\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0336 - val_loss: 0.0588\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0192 - val_loss: 0.0658\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0209 - val_loss: 0.0661\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0193 - val_loss: 0.0601\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0230 - val_loss: 0.0482\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0127 - val_loss: 0.0350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0040\n",
      "Loss: 0.0040424237959086895\n",
      "Treinando com seq_len=5, units=128, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1167 - val_loss: 0.0028\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0551 - val_loss: 0.0114\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0255 - val_loss: 0.0322\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0087 - val_loss: 0.0478\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0191 - val_loss: 0.0433\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0207 - val_loss: 0.0274\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0215 - val_loss: 0.0117\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0158 - val_loss: 0.0038\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0038 - val_loss: 0.0079\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0055 - val_loss: 0.0118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0028\n",
      "Loss: 0.002770910505205393\n",
      "Treinando com seq_len=5, units=128, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1071 - val_loss: 0.0125\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0565 - val_loss: 0.0326\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0279 - val_loss: 0.0466\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0163 - val_loss: 0.0419\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0151 - val_loss: 0.0245\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0146 - val_loss: 0.0089\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0102 - val_loss: 0.0033\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0054 - val_loss: 0.0193\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0080 - val_loss: 0.0258\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0128 - val_loss: 0.0252\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0104 - val_loss: 0.0198\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0082 - val_loss: 0.0129\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0020 - val_loss: 0.0054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0033\n",
      "Loss: 0.0032723871991038322\n",
      "Treinando com seq_len=5, units=128, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1077 - val_loss: 0.0031\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0423 - val_loss: 0.0173\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0134 - val_loss: 0.0399\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0208 - val_loss: 0.0425\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0220 - val_loss: 0.0291\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0201 - val_loss: 0.0131\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0124 - val_loss: 0.0041\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0107 - val_loss: 0.0037\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0039 - val_loss: 0.0095\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0072 - val_loss: 0.0163\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0097 - val_loss: 0.0195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0031\n",
      "Loss: 0.0031237362418323755\n",
      "Treinando com seq_len=7, units=32, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1665 - val_loss: 0.0109\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1501 - val_loss: 0.0052\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1031 - val_loss: 0.0034\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0912 - val_loss: 0.0045\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0642 - val_loss: 0.0079\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0556 - val_loss: 0.0133\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0321 - val_loss: 0.0193\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0256 - val_loss: 0.0253\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0243 - val_loss: 0.0313\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0215 - val_loss: 0.0359\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0298 - val_loss: 0.0372\n",
      "Epoch 12/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0176 - val_loss: 0.0360\n",
      "Epoch 13/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0233 - val_loss: 0.0320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0034\n",
      "Loss: 0.0033584225457161665\n",
      "Treinando com seq_len=7, units=32, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0427 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0302 - val_loss: 0.0069\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0166 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0103 - val_loss: 0.0033\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0037 - val_loss: 0.0050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0033\n",
      "Loss: 0.0033116377890110016\n",
      "Treinando com seq_len=7, units=32, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0825 - val_loss: 0.0105\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0669 - val_loss: 0.0048\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0394 - val_loss: 0.0037\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0288 - val_loss: 0.0066\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0182 - val_loss: 0.0121\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0086 - val_loss: 0.0184\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0084 - val_loss: 0.0229\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0081 - val_loss: 0.0255\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0142 - val_loss: 0.0257\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0164 - val_loss: 0.0230\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 12/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0132 - val_loss: 0.0140\n",
      "Epoch 13/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0165 - val_loss: 0.0098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037\n",
      "Loss: 0.0036650756374001503\n",
      "Treinando com seq_len=7, units=64, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0798 - val_loss: 0.0035\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0221 - val_loss: 0.0099\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0132 - val_loss: 0.0278\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0093 - val_loss: 0.0442\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0177 - val_loss: 0.0433\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0274 - val_loss: 0.0310\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0253 - val_loss: 0.0169\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0043 - val_loss: 0.0071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0035\n",
      "Loss: 0.0034958149772137403\n",
      "Treinando com seq_len=7, units=64, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0711 - val_loss: 0.0129\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0446 - val_loss: 0.0254\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0285 - val_loss: 0.0297\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0140 - val_loss: 0.0264\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0113 - val_loss: 0.0175\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0167 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0109 - val_loss: 0.0035\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0116 - val_loss: 0.0053\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0083 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0098 - val_loss: 0.0208\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0087 - val_loss: 0.0266\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0080 - val_loss: 0.0292\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0110 - val_loss: 0.0283\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0109 - val_loss: 0.0246\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0069 - val_loss: 0.0196\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0066 - val_loss: 0.0144\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0048 - val_loss: 0.0101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0035\n",
      "Loss: 0.0034732595086097717\n",
      "Treinando com seq_len=7, units=64, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.1143 - val_loss: 0.0047\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0812 - val_loss: 0.0038\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0431 - val_loss: 0.0097\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0278 - val_loss: 0.0196\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0141 - val_loss: 0.0279\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0106 - val_loss: 0.0328\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0107 - val_loss: 0.0316\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0147 - val_loss: 0.0244\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0107 - val_loss: 0.0158\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0150 - val_loss: 0.0082\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0092 - val_loss: 0.0040\n",
      "Epoch 12/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0038\n",
      "Loss: 0.0038112548645585775\n",
      "Treinando com seq_len=7, units=128, epochs=30...\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0602 - val_loss: 0.0202\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0206 - val_loss: 0.0276\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0092 - val_loss: 0.0188\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0065 - val_loss: 0.0137\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0090 - val_loss: 0.0212\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0070 - val_loss: 0.0204\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0094 - val_loss: 0.0136\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 12/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 13/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 14/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0021 - val_loss: 0.0099\n",
      "Epoch 15/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0028 - val_loss: 0.0117\n",
      "Epoch 16/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0027 - val_loss: 0.0118\n",
      "Epoch 17/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0028 - val_loss: 0.0105\n",
      "Epoch 18/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 19/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 20/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 21/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0039\n",
      "Loss: 0.003908673767000437\n",
      "Treinando com seq_len=7, units=128, epochs=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0602 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747ms/step - loss: 0.0151 - val_loss: 0.0295\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0120 - val_loss: 0.0257\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0164 - val_loss: 0.0103\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0126 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0040 - val_loss: 0.0162\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0069 - val_loss: 0.0206\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0077 - val_loss: 0.0192\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0065 - val_loss: 0.0144\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0017 - val_loss: 0.0053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0031\n",
      "Loss: 0.0030641204211860895\n",
      "Treinando com seq_len=7, units=128, epochs=70...\n",
      "Epoch 1/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.0689 - val_loss: 0.0107\n",
      "Epoch 2/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0215 - val_loss: 0.0312\n",
      "Epoch 3/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0149 - val_loss: 0.0259\n",
      "Epoch 4/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0162 - val_loss: 0.0087\n",
      "Epoch 5/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0102 - val_loss: 0.0034\n",
      "Epoch 6/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0080 - val_loss: 0.0119\n",
      "Epoch 7/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0060 - val_loss: 0.0218\n",
      "Epoch 8/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0088 - val_loss: 0.0250\n",
      "Epoch 9/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0059 - val_loss: 0.0226\n",
      "Epoch 10/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0075 - val_loss: 0.0163\n",
      "Epoch 11/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 12/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 13/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 14/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 9.0314e-04 - val_loss: 0.0051\n",
      "Epoch 15/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0015 - val_loss: 0.0087\n",
      "Epoch 16/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0031 - val_loss: 0.0122\n",
      "Epoch 17/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0033 - val_loss: 0.0144\n",
      "Epoch 18/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0028 - val_loss: 0.0150\n",
      "Epoch 19/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0062 - val_loss: 0.0138\n",
      "Epoch 20/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0037 - val_loss: 0.0114\n",
      "Epoch 21/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0031 - val_loss: 0.0086\n",
      "Epoch 22/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 23/70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0034\n",
      "Loss: 0.003413206897675991\n",
      "Melhores parâmetros encontrados: {'sequence_length': 5, 'units': 32, 'epochs': 30}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importações adicionais\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Função para criar e treinar o modelo LSTM\n",
    "def train_lstm_model(X_train, y_train, X_test, y_test, units, epochs, sequence_length):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Adicionando early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=16, \n",
    "                        validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Experimentos com diferentes tamanhos de janelas, épocas e unidades\n",
    "sequence_lengths = [3, 5, 7]  # Tamanhos das janelas\n",
    "units_list = [32, 64, 128]    # Unidades LSTM\n",
    "epochs_list = [30, 50, 70]    # Número de épocas\n",
    "\n",
    "# Variáveis para armazenar os melhores resultados\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Loop para experimentar diferentes combinações de hiperparâmetros\n",
    "for seq_len in sequence_lengths:\n",
    "    X, y = create_sequences(df_scaled, seq_len)\n",
    "    train_size = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    for units in units_list:\n",
    "        for epochs in epochs_list:\n",
    "            print(f\"Treinando com seq_len={seq_len}, units={units}, epochs={epochs}...\")\n",
    "            model, history = train_lstm_model(X_train, y_train, X_test, y_test, units, epochs, seq_len)\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            loss = model.evaluate(X_test, y_test)\n",
    "            print(f\"Loss: {loss}\")\n",
    "            \n",
    "            # Se o modelo atual for melhor, atualize os melhores resultados\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_model = model\n",
    "                best_params = {'sequence_length': seq_len, 'units': units, 'epochs': epochs}\n",
    "\n",
    "print(f\"Melhores parâmetros encontrados: {best_params}\")\n",
    "\n",
    "# Fazer previsões com o melhor modelo\n",
    "X, y = create_sequences(df_scaled, best_params['sequence_length'])\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "predictions_rescaled = scaler.inverse_transform(\n",
    "    np.concatenate([np.zeros((predictions.shape[0], X_test.shape[2])), predictions], axis=1))[:, -1]\n",
    "\n",
    "# Visualizar previsões e valores reais\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_pais['Ano'][train_size+best_params['sequence_length']:], y_test, label='Real')\n",
    "plt.plot(df_pais['Ano'][train_size+best_params['sequence_length']:], predictions_rescaled, label='Previsto')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
